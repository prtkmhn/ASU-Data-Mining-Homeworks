# -*- coding: utf-8 -*-
"""HW1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EHAr4G3axeRH5Y9SmDdTNwnHeQooQ8QS
"""

from google.colab import drive
drive.mount('/content/drive')
import numpy as np
import random
from tqdm import tqdm
import pandas as pd
import string
import nltk
nltk.download('punkt')
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem.porter import *

train_data_path = '/content/drive/My Drive/Colab Notebooks/24_train_1.csv'
test_data_path = '/content/drive/My Drive/Colab Notebooks/news-test.csv'

# Load data
train_data = pd.read_csv(train_data_path)
test_data = pd.read_csv(test_data_path)

# Display the first few rows of the training data to ensure it loaded correctly
print(train_data.head())

# stemming tool from nltk
stemmer = PorterStemmer()
# a mapping dictionary that helps remove punctuations
remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)

def preprocess_text(text):
    # turn document into lowercase
    lowers = text.lower()
    # remove punctuation
    no_punctuation = lowers.translate(remove_punctuation_map)
    # tokenize document
    tokens = nltk.word_tokenize(no_punctuation)
    # stop words
    filtered = [w for w in tokens if not w in stopwords.words("english")]
    # stemming process
    stemmed = [stemmer.stem(item) for item in filtered]

    return " ".join(stemmed)

# Apply preprocessing to the entire training dataset
train_data['Processed_Text'] = train_data['Text'].apply(preprocess_text)

# Display the first few rows of the processed training data
print(train_data[['ArticleId', 'Processed_Text', 'Category']].head())

# Apply preprocessing to the entire testing dataset
test_data['Processed_Text'] = test_data['Text'].apply(preprocess_text)

# Display the first few rows of the processed testing data
print(test_data[['ArticleId', 'Processed_Text']].head())

"""# 1. Evaluate the Decision Tree Model on Preprocessed Data"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Split the data into features and target
X = train_data['Processed_Text']
y = train_data['Category']

# Convert the text to a matrix of token counts
from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(X)

# Step 1: Initialize the Decision Tree Classifier with default params
dt_classifier = DecisionTreeClassifier()

# Step 2: Split your data (80% train, 20% validation)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 3: Fit the model
dt_classifier.fit(X_train, y_train)

# Step 4: Predict on the validation set
y_pred_val = dt_classifier.predict(X_val)

# Step 5: Evaluate the accuracy of the model
accuracy = accuracy_score(y_val, y_pred_val)
print(f"Validation Accuracy of the Decision Tree model is: {accuracy}")

"""# Train-Validation Split and Parameter Tuning"""

import matplotlib.pyplot as plt

# Function to train the model and evaluate it on both train and validation sets
def evaluate_decision_tree(criterion_type):
    dt_classifier = DecisionTreeClassifier(criterion=criterion_type)
    dt_classifier.fit(X_train, y_train)
    y_train_pred = dt_classifier.predict(X_train)
    y_val_pred = dt_classifier.predict(X_val)

    train_accuracy = accuracy_score(y_train, y_train_pred)
    val_accuracy = accuracy_score(y_val, y_val_pred)

    return train_accuracy, val_accuracy

results = []

# Loop over the criterion types
for criterion in ['gini', 'entropy']:
    train_acc, val_acc = evaluate_decision_tree(criterion)
    results.append({
        'Criterion': criterion,
        'Training Accuracy': train_acc,
        'Validation Accuracy': val_acc
    })

# Convert the results to a dataframe for easier plotting
results_df = pd.DataFrame(results)

# Plot a bar chart
results_df.plot(x='Criterion', y=['Training Accuracy', 'Validation Accuracy'], kind='bar')
plt.title('Decision Tree Accuracy w.r.t. Criterion Type')
plt.ylabel('Accuracy')
plt.show()

"""# Cross-Validation"""

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# Separate input features and target
X = train_data['Processed_Text']
y = train_data['Category']

# Encoding categorical data
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

# We need to convert text data into numerical data for decision tree using TfidfVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer()
X_vectorized = vectorizer.fit_transform(X)

# Split the data
X_train, X_val, y_train, y_val = train_test_split(X_vectorized, y_encoded, test_size=0.2)

# Decision Tree with different criterion
criterions = ['gini', 'entropy']
train_accuracies = []
val_accuracies = []

for criterion in criterions:
    tree = DecisionTreeClassifier(criterion=criterion)
    tree.fit(X_train, y_train)
    y_train_pred = tree.predict(X_train)
    y_val_pred = tree.predict(X_val)

    train_accuracies.append(accuracy_score(y_train, y_train_pred))
    val_accuracies.append(accuracy_score(y_val, y_val_pred))

# Plot bar chart
plt.bar(criterions, train_accuracies, width=0.4, label='Training Accuracy')
plt.bar(criterions, val_accuracies, width=0.4, label='Validation Accuracy', alpha=0.7)
plt.xlabel('Criterion')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

from sklearn.model_selection import cross_val_score, cross_validate

# Possible min_samples_leaf values
min_samples_leaf_values = [10, 50, 100, 150, 200]

# To store average scores
avg_train_scores = []
avg_val_scores = []

for min_samples_leaf in min_samples_leaf_values:
    tree = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf)
    # Perform 5-fold cross-validation
    scores = cross_validate(tree, X_vectorized, y_encoded, cv=5, return_train_score=True)

    # Store average training and validation scores
    avg_train_scores.append((min_samples_leaf, np.mean(scores['train_score']), np.std(scores['train_score'])))
    avg_val_scores.append((min_samples_leaf, np.mean(scores['test_score']), np.std(scores['test_score'])))

# Convert to pandas DataFrame
df_train_scores = pd.DataFrame(avg_train_scores, columns=['min_samples_leaf', 'training accuracy', 'training std'])
df_val_scores = pd.DataFrame(avg_val_scores, columns=['min_samples_leaf', 'validation accuracy', 'validation std'])

# Display the results
print("Average Training Scores:\n", df_train_scores)
print("\nAverage Validation Scores:\n", df_val_scores)

# Plotting line chart
plt.errorbar(df_train_scores['min_samples_leaf'], df_train_scores['training accuracy'], yerr=df_train_scores['training std'], label='Training Accuracy')
plt.errorbar(df_val_scores['min_samples_leaf'], df_val_scores['validation accuracy'], yerr=df_val_scores['validation std'], label='Validation Accuracy', linestyle='--')
plt.xlabel('min_samples_leaf')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Possible max_features values (assuming X.shape[1] is the number of features)
max_features_values = [None, 'sqrt', 'log2', 0.5, 0.7, 0.9]

# Rest is the same as for min_samples_leaf
avg_train_scores = []
avg_val_scores = []

for max_features in max_features_values:
    tree = DecisionTreeClassifier(max_features=max_features)
    scores = cross_validate(tree, X_vectorized, y_encoded, cv=5, return_train_score=True)

    avg_train_scores.append((max_features, np.mean(scores['train_score']), np.std(scores['train_score'])))
    avg_val_scores.append((max_features, np.mean(scores['test_score']), np.std(scores['test_score'])))

df_train_scores = pd.DataFrame(avg_train_scores, columns=['max_features', 'training accuracy', 'training std'])
df_val_scores = pd.DataFrame(avg_val_scores, columns=['max_features', 'validation accuracy', 'validation std'])

print("Average Training Scores:\n", df_train_scores)
print("\nAverage Validation Scores:\n", df_val_scores)

# Plot the line chart for max_features
plt.figure(figsize=(10, 4))
plt.errorbar([str(feat) for feat in df_train_scores['max_features']], df_train_scores['training accuracy'], yerr=df_train_scores['training std'], label='Training Accuracy')
plt.errorbar([str(feat) for feat in df_val_scores['max_features']], df_val_scores['validation accuracy'], yerr=df_val_scores['validation std'], label='Validation Accuracy', linestyle='--')
plt.xlabel('max_features')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

"""# Evaluate Random Forest Model"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_validate
import numpy as np
import matplotlib.pyplot as plt

# Describe parameter settings
# For example, we choose 100 trees and min_samples_leaf as 5
n_estimators = [50, 100, 150, 200]
min_samples_leaf_values = [1, 5, 10, 20]

# Store average scores for n_estimators
avg_n_estimators_train_scores = []
avg_n_estimators_val_scores = []

# Store average scores for min_samples_leaf
avg_min_samples_leaf_train_scores = []
avg_min_samples_leaf_val_scores = []

# Random Forest with different number of trees (n_estimators)
for est in n_estimators:
    rf = RandomForestClassifier(n_estimators=est)
    scores = cross_validate(rf, X_vectorized, y_encoded, cv=5, return_train_score=True)
    avg_n_estimators_train_scores.append((est, np.mean(scores['train_score']), np.std(scores['train_score'])))
    avg_n_estimators_val_scores.append((est, np.mean(scores['test_score']), np.std(scores['test_score'])))

# Random Forest with different min_samples_leaf values
for min_leaf in min_samples_leaf_values:
    rf = RandomForestClassifier(min_samples_leaf=min_leaf)
    scores = cross_validate(rf, X_vectorized, y_encoded, cv=5, return_train_score=True)
    avg_min_samples_leaf_train_scores.append((min_leaf, np.mean(scores['train_score']), np.std(scores['train_score'])))
    avg_min_samples_leaf_val_scores.append((min_leaf, np.mean(scores['test_score']), np.std(scores['test_score'])))

# Convert to pandas DataFrame
df_n_estimators_train_scores = pd.DataFrame(avg_n_estimators_train_scores, columns=['n_estimators', 'training accuracy', 'training std'])
df_n_estimators_val_scores = pd.DataFrame(avg_n_estimators_val_scores, columns=['n_estimators', 'validation accuracy', 'validation std'])

df_min_samples_leaf_train_scores = pd.DataFrame(avg_min_samples_leaf_train_scores, columns=['min_samples_leaf', 'training accuracy', 'training std'])
df_min_samples_leaf_val_scores = pd.DataFrame(avg_min_samples_leaf_val_scores, columns=['min_samples_leaf', 'validation accuracy', 'validation std'])

# Display the results
print("Average Training Scores for n_estimators:\n", df_n_estimators_train_scores)
print("\nAverage Validation Scores for n_estimators:\n", df_n_estimators_val_scores)
print("\nAverage Training Scores for min_samples_leaf:\n", df_min_samples_leaf_train_scores)
print("\nAverage Validation Scores for min_samples_leaf:\n", df_min_samples_leaf_val_scores)

# Plotting line chart for n_estimators
plt.figure(figsize=(10, 4))
plt.errorbar(df_n_estimators_train_scores['n_estimators'], df_n_estimators_train_scores['training accuracy'], yerr=df_n_estimators_train_scores['training std'], label='Training Accuracy')
plt.errorbar(df_n_estimators_val_scores['n_estimators'], df_n_estimators_val_scores['validation accuracy'], yerr=df_n_estimators_val_scores['validation std'], label='Validation Accuracy', linestyle='--')
plt.xlabel('n_estimators')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plotting line chart for min_samples_leaf
plt.figure(figsize=(10, 4))
plt.errorbar(df_min_samples_leaf_train_scores['min_samples_leaf'], df_min_samples_leaf_train_scores['training accuracy'], yerr=df_min_samples_leaf_train_scores['training std'], label='Training Accuracy')
plt.errorbar(df_min_samples_leaf_val_scores['min_samples_leaf'], df_min_samples_leaf_val_scores['validation accuracy'], yerr=df_min_samples_leaf_val_scores['validation std'], label='Validation Accuracy', linestyle='--')
plt.xlabel('min_samples_leaf')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

from sklearn.model_selection import cross_val_score, cross_validate
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt

# Decision Tree Evaluation with different criteria
def evaluate_decision_tree(criterion_type):
    dt_classifier = DecisionTreeClassifier(criterion=criterion_type)
    dt_classifier.fit(X_train, y_train)
    y_train_pred = dt_classifier.predict(X_train)
    y_val_pred = dt_classifier.predict(X_val)

    train_accuracy = accuracy_score(y_train, y_train_pred)
    val_accuracy = accuracy_score(y_val, y_val_pred)

    return train_accuracy, val_accuracy

# Loop over the criterion types
results_dt = []

for criterion in ['gini', 'entropy']:
    train_acc, val_acc = evaluate_decision_tree(criterion)
    results_dt.append({
        'Criterion': criterion,
        'Training Accuracy': train_acc,
        'Validation Accuracy': val_acc
    })

# Convert the results to a dataframe for easier plotting
results_df_dt = pd.DataFrame(results_dt)

# Plot a bar chart for Decision Tree Accuracy w.r.t. Criterion Type
results_df_dt.plot(x='Criterion', y=['Training Accuracy', 'Validation Accuracy'], kind='bar')
plt.title('Decision Tree Accuracy w.r.t. Criterion Type')
plt.ylabel('Accuracy')
plt.show()

# Decision Tree Evaluation with 5-fold cross-validation w.r.t min_samples_leaf
min_samples_leaf_values = [10, 50, 100, 150, 200]

avg_train_scores_dt = []
avg_val_scores_dt = []

for min_samples_leaf in min_samples_leaf_values:
    tree = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf)
    scores = cross_validate(tree, X_vectorized, y_encoded, cv=5, return_train_score=True)

    avg_train_scores_dt.append((min_samples_leaf, np.mean(scores['train_score']), np.std(scores['train_score'])))
    avg_val_scores_dt.append((min_samples_leaf, np.mean(scores['test_score']), np.std(scores['test_score'])))

# Convert to pandas DataFrame
df_train_scores_dt = pd.DataFrame(avg_train_scores_dt, columns=['min_samples_leaf', 'training accuracy', 'training std'])
df_val_scores_dt = pd.DataFrame(avg_val_scores_dt, columns=['min_samples_leaf', 'validation accuracy', 'validation std'])

# Display the results for Decision Tree with min_samples_leaf
print("Average Training Scores for Decision Tree:\n", df_train_scores_dt)
print("\nAverage Validation Scores for Decision Tree:\n", df_val_scores_dt)

# Plotting line chart for Decision Tree with min_samples_leaf
plt.errorbar(df_train_scores_dt['min_samples_leaf'], df_train_scores_dt['training accuracy'], yerr=df_train_scores_dt['training std'], label='Training Accuracy')
plt.errorbar(df_val_scores_dt['min_samples_leaf'], df_val_scores_dt['validation accuracy'], yerr=df_val_scores_dt['validation std'], label='Validation Accuracy', linestyle='--')
plt.xlabel('min_samples_leaf')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Decision Tree Evaluation with 5-fold cross-validation w.r.t max_features
max_features_values_dt = [None, 'sqrt', 'log2', 0.5, 0.7, 0.9]

avg_train_scores_dt_features = []
avg_val_scores_dt_features = []

for max_features in max_features_values_dt:
    tree = DecisionTreeClassifier(max_features=max_features)
    scores = cross_validate(tree, X_vectorized, y_encoded, cv=5, return_train_score=True)

    avg_train_scores_dt_features.append((max_features, np.mean(scores['train_score']), np.std(scores['train_score'])))
    avg_val_scores_dt_features.append((max_features, np.mean(scores['test_score']), np.std(scores['test_score'])))

# Convert to pandas DataFrame
df_train_scores_dt_features = pd.DataFrame(avg_train_scores_dt_features, columns=['max_features', 'training accuracy', 'training std'])
df_val_scores_dt_features = pd.DataFrame(avg_val_scores_dt_features, columns=['max_features', 'validation accuracy', 'validation std'])

# Display the results for Decision Tree with max_features
print("Average Training Scores for Decision Tree (max_features):\n", df_train_scores_dt_features)
print("\nAverage Validation Scores for Decision Tree (max_features):\n", df_val_scores_dt_features)

# Plotting line chart for Decision Tree with max_features
plt.figure(figsize=(10, 4))
plt.errorbar([str(feat) for feat in df_train_scores_dt_features['max_features']], df_train_scores_dt_features['training accuracy'], yerr=df_train_scores_dt_features['training std'], label='Training Accuracy')
plt.errorbar([str(feat) for feat in df_val_scores_dt_features['max_features']], df_val_scores_dt_features['validation accuracy'], yerr=df_val_scores_dt_features['validation std'], label='Validation Accuracy', linestyle='--')
plt.xlabel('max_features')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Random Forest Evaluation on pre-processed training data
def evaluate_random_forest(n_estimators, min_samples_leaf):
    rf_classifier = RandomForestClassifier(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf)
    scores = cross_validate(rf_classifier, X_vectorized, y_encoded, cv=5, return_train_score=True)

    avg_train_accuracy = np.mean(scores['train_score'])
    avg_val_accuracy = np.mean(scores['test_score'])

    return avg_train_accuracy, avg_val_accuracy

# Store average scores for Random Forest
avg_n_estimators_train_scores_rf = []
avg_n_estimators_val_scores_rf = []
avg_min_samples_leaf_train_scores_rf = []
avg_min_samples_leaf_val_scores_rf = []

# Random Forest with different number of trees (n_estimators)
for est in n_estimators:
    avg_train_acc_rf, avg_val_acc_rf = evaluate_random_forest(est, 5)
    avg_n_estimators_train_scores_rf.append((est, avg_train_acc_rf))
    avg_n_estimators_val_scores_rf.append((est, avg_val_acc_rf))

# Random Forest with different min_samples_leaf values
for min_leaf in min_samples_leaf_values:
    avg_train_acc_rf, avg_val_acc_rf = evaluate_random_forest(100, min_leaf)
    avg_min_samples_leaf_train_scores_rf.append((min_leaf, avg_train_acc_rf))
    avg_min_samples_leaf_val_scores_rf.append((min_leaf, avg_val_acc_rf))

# Convert to pandas DataFrame
df_n_estimators_train_scores_rf = pd.DataFrame(avg_n_estimators_train_scores_rf, columns=['n_estimators', 'training accuracy'])
df_n_estimators_val_scores_rf = pd.DataFrame(avg_n_estimators_val_scores_rf, columns=['n_estimators', 'validation accuracy'])
df_min_samples_leaf_train_scores_rf = pd.DataFrame(avg_min_samples_leaf_train_scores_rf, columns=['min_samples_leaf', 'training accuracy'])
df_min_samples_leaf_val_scores_rf = pd.DataFrame(avg_min_samples_leaf_val_scores_rf, columns=['min_samples_leaf', 'validation accuracy'])

# Display the results for Random Forest
print("Average Training Scores for Random Forest (n_estimators):\n", df_n_estimators_train_scores_rf)
print("\nAverage Validation Scores for Random Forest (n_estimators):\n", df_n_estimators_val_scores_rf)
print("\nAverage Training Scores for Random Forest (min_samples_leaf):\n", df_min_samples_leaf_train_scores_rf)
print("\nAverage Validation Scores for Random Forest (min_samples_leaf):\n", df_min_samples_leaf_val_scores_rf)

# Plotting line chart for Random Forest with n_estimators
plt.figure(figsize=(10, 4))
plt.plot(df_n_estimators_train_scores_rf['n_estimators'], df_n_estimators_train_scores_rf['training accuracy'], label='Training Accuracy')
plt.plot(df_n_estimators_val_scores_rf['n_estimators'], df_n_estimators_val_scores_rf['validation accuracy'], label='Validation Accuracy', linestyle='--')
plt.xlabel('n_estimators')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plotting line chart for Random Forest with min_samples_leaf
plt.figure(figsize=(10, 4))
plt.plot(df_min_samples_leaf_train_scores_rf['min_samples_leaf'], df_min_samples_leaf_train_scores_rf['training accuracy'], label='Training Accuracy')
plt.plot(df_min_samples_leaf_val_scores_rf['min_samples_leaf'], df_min_samples_leaf_val_scores_rf['validation accuracy'], label='Validation Accuracy', linestyle='--')
plt.xlabel('min_samples_leaf')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_validate
import numpy as np
import matplotlib.pyplot as plt

# Load the raw test data

test_data_raw = pd.read_csv('/content/drive/My Drive/Colab Notebooks/news-test.csv')

# Apply the same preprocessing steps to the test data
test_data_raw['Processed_Text'] = test_data_raw['Text'].apply(preprocess_text)

# Re-fit the vectorizer on the training data and transform the test data
X_vectorized = vectorizer.fit_transform(train_data['Processed_Text'])
X_test_vectorized = vectorizer.transform(test_data_raw['Processed_Text'])

# Chosen model: Random Forest
# Chosen parameters: n_estimators=100, min_samples_leaf=5 (as per reference code)
rf_classifier_final = RandomForestClassifier(n_estimators=100, min_samples_leaf=5)

# Fit the model on the entire pre-processed training data
rf_classifier_final.fit(X_vectorized, y_encoded)

# Predict labels for the test data
y_test_pred = rf_classifier_final.predict(X_test_vectorized)

# Map category numbers to names
category_names = encoder.inverse_transform(y_test_pred)

# Convert 'ArticleId' to string
test_data_raw['ArticleId'] = test_data_raw['ArticleId'].astype(str)

# Save the predictions to labels.csv in the correct format
predictions_df = pd.DataFrame({'ArticleId': test_data_raw['ArticleId'], 'Category': category_names})
predictions_df['ArticleId_Category'] = predictions_df['ArticleId'] + ',' + predictions_df['Category'].astype(str)
predictions_df[['ArticleId_Category']].to_csv('/content/drive/My Drive/Colab Notebooks/labels.csv', index=False, header=False)

# Print predictions for testing data
print(predictions_df)

