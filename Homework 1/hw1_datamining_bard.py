# -*- coding: utf-8 -*-
"""HW1_DataMining_Bard.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cxL72PMVZmezHwUipw9LjhTyjOY_yJMS
"""

from google.colab import drive
import numpy as np
import pandas as pd
import string
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import *
from sklearn.feature_extraction.text import CountVectorizer
nltk.download('punkt')
nltk.download('stopwords')

# Mount Google Drive
drive.mount('/content/drive')

# Load data
train_data_path = '/content/drive/My Drive/Colab Notebooks/24_train_1.csv'
test_data_path = '/content/drive/My Drive/Colab Notebooks/news-test.csv'
train_data = pd.read_csv(train_data_path)
test_data = pd.read_csv(test_data_path)
stemmer = PorterStemmer()
# Preprocessing function
def preprocess_text(text):
    # Lowercase, remove punctuation, tokenize
    tokens = nltk.word_tokenize(text.lower().translate(str.maketrans('', '', string.punctuation)))

    # Remove stop words and stem
    filtered_tokens = [stemmer.stem(w) for w in tokens if w not in stopwords.words("english")]

    return " ".join(filtered_tokens)

# Apply preprocessing to both datasets
train_data['Processed_Text'] = train_data['Text'].apply(preprocess_text)
test_data['Processed_Text'] = test_data['Text'].apply(preprocess_text)

# Convert preprocessed text to numerical features (BoW)
vectorizer = CountVectorizer()
train_features = vectorizer.fit_transform(train_data['Processed_Text'])
test_features = vectorizer.transform(test_data['Processed_Text'])

print(train_data[['ArticleId', 'Processed_Text', 'Category']].head(3))
print(test_data[['ArticleId', 'Processed_Text']].head(3))

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, cross_validate
import matplotlib.pyplot as plt

# Assuming you have preprocessed data and features from previous steps
X_train = train_features  # Numerical features from training data
y_train = train_data['Category']  # Target labels

# Split data into 80% training and 20% validation
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Define model with placeholders for criterion value
model = DecisionTreeClassifier(criterion="placeholder")

# List of criterion values to try
criterion_values = ["gini", "entropy"]

# Store results for each criterion
results = {}

for criterion in criterion_values:
    model.set_params(criterion=criterion)  # Set the criterion for each iteration

    # Use cross-validation to get training and validation accuracies
    cv_results = cross_validate(model, X_train, y_train, cv=5, return_train_score=True)

    results[criterion] = {
        "train_accuracy": cv_results["train_score"].mean(),
        "val_accuracy": cv_results["test_score"].mean()
    }

# Create bar chart
plt.figure(figsize=(8, 5))
bar_width = 0.4

# Convert keys to numerical positions for proper bar placement
x_positions = range(len(results))  # Generate numerical positions for each criterion

plt.bar(x_positions, [result["train_accuracy"] for result in results.values()], width=bar_width, label="Training Accuracy")
plt.bar([x + bar_width for x in x_positions], [result["val_accuracy"] for result in results.values()], width=bar_width, label="Validation Accuracy")

# Set x-axis tick labels to criterion names
plt.xticks([x + bar_width / 2 for x in x_positions], results.keys())

plt.xlabel("Criterion")
plt.ylabel("Accuracy")
plt.title("Decision Tree Accuracy with Different Criterion Values")
plt.legend()
plt.show()

"""#evaluating the decision tree model with min_samples_leaf and max_features"""

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_validate, StratifiedKFold
import matplotlib.pyplot as plt

# Assuming you have preprocessed data and features from previous steps
X_train = train_features
y_train = train_data['Category']

# Define evaluation functions
def evaluate_model(model, param_name, param_values):
    results = {}
    for value in param_values:
        model.set_params(**{param_name: value})
        cv_results = cross_validate(model, X_train, y_train, cv=5, return_train_score=True)
        results[value] = {
            "train_accuracy": cv_results["train_score"].mean(),
            "val_accuracy": cv_results["test_score"].mean(),
            "train_std": cv_results["train_score"].std(),
            "val_std": cv_results["test_score"].std()
        }
    return results

def plot_results(results, param_name):
    param_values = list(results.keys())
    train_accuracies = [result["train_accuracy"] for result in results.values()]
    val_accuracies = [result["val_accuracy"] for result in results.values()]

    plt.figure(figsize=(8, 5))
    plt.plot(param_values, train_accuracies, label="Training Accuracy")
    plt.plot(param_values, val_accuracies, label="Validation Accuracy")
    plt.xlabel(param_name)
    plt.ylabel("Accuracy")
    plt.title(f"Decision Tree Accuracy with Different {param_name} Values")
    plt.legend()
    plt.show()

# Evaluate with min_samples_leaf
model = DecisionTreeClassifier()
min_samples_leaf_values = [10, 50, 100, 200]
results = evaluate_model(model, "min_samples_leaf", min_samples_leaf_values)
print(pd.DataFrame(results).to_string())  # Print results as a table
plot_results(results, "min_samples_leaf")

# Evaluate with max_features
max_features_values = ["auto", "sqrt", "log2"]
results = evaluate_model(model, "max_features", max_features_values)
print(pd.DataFrame(results).to_string())
plot_results(results, "max_features")

"""#evaluating the random forest model with n_estimators and min_samples_leaf"""

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_validate, StratifiedKFold
import matplotlib.pyplot as plt

# Assuming you have preprocessed data and features from previous steps
X_train = train_features
y_train = train_data['Category']

# Define the random forest model
model = RandomForestClassifier(n_estimators=100, min_samples_leaf=20)  # Initial parameters

# Evaluate with n_estimators
n_estimators_values = [50, 100, 200, 500]
results = evaluate_model(model, "n_estimators", n_estimators_values)  # Reuse the evaluation functions
print(pd.DataFrame(results).to_string())
plot_results(results, "n_estimators")

# Evaluate with min_samples_leaf
min_samples_leaf_values = [10, 20, 50, 100]
results = evaluate_model(model, "min_samples_leaf", min_samples_leaf_values)
print(pd.DataFrame(results).to_string())
plot_results(results, "min_samples_leaf")

"""#predicting labels on testing data"""

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

# Assuming you have preprocessed training and testing data
X_train = train_features
y_train = train_data['Category']
X_test = test_features  # Preprocessed testing data

# Choose the best model and parameters based on cross-validation results
# (replace with your chosen model and parameters)
best_model = RandomForestClassifier(n_estimators=200, min_samples_leaf=50)

# Train the final model on the entire training data
best_model.fit(X_train, y_train)

# Predict labels for the testing data
y_pred = best_model.predict(X_test)

# Print or save the predicted labels
print(y_pred)